import type { RaycastAIModels } from '@ru/shared'

export const OPENAI_SERVICE_PROVIDERS: RaycastAIModels = [
  {
    id: 'openai-gpt-3.5-turbo',
    description: 'GPT-3.5 Turbo is OpenAIâ€™s fastest model, making it ideal for tasks that require quick response times with basic language processing capabilities.\n',
    model: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    speed: 3,
    intelligence: 3,
    provider: 'openai',
    provider_name: 'OpenAI',
    provider_brand: 'openai',
    requires_better_ai: false,
    context: 16,
    capabilities: { web_search: 'full' },
    suggestions: ['chat', 'quick_ai', 'commands'],
    in_better_ai_subscription: false,
    status: null,
  },
]

export const GROQ_SERVICE_PROVIDERS: RaycastAIModels = [
  {
    id: 'gemma-7b-it',
    model: 'gemma-7b-it',
    name: 'Gemma 7B It',
    description: `Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.\n`,
    provider: 'groq',
    provider_name: 'Google',
    provider_brand: 'google',
    requires_better_ai: false,
    speed: 5,
    intelligence: 3,
    context: 7,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {},
    in_better_ai_subscription: false,
    status: null,
  },
  {
    id: 'llama2-70b-4096',
    model: 'llama2-70b-4096',
    name: 'Llama 2 70B 4096',
    description: `Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters.\n`,
    provider: 'groq',
    provider_name: 'Meta',
    provider_brand: 'meta',
    requires_better_ai: true,
    speed: 5,
    intelligence: 3,
    context: 8,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {},
    in_better_ai_subscription: true,
    status: 'deprecated',
    availability: 'deprecated',
  },
  {
    id: 'llama3-8b-8192',
    model: 'llama3-8b-8192',
    name: 'Llama 3 8B 8192',
    description: `Llama 3 is a collection of pretrained and fine-tuned generative text models ranging in scale from 8 billion to 70 billion parameters.\n`,
    provider: 'groq',
    provider_name: 'Meta',
    provider_brand: 'meta',
    requires_better_ai: true,
    speed: 5,
    intelligence: 3,
    context: 8,
    suggestions: ['quick_ai'],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {},
    in_better_ai_subscription: true,
    status: null,
  },
  {
    id: 'llama3-70b-8192',
    model: 'llama3-70b-8192',
    name: 'Llama 3 70B 8192',
    description: `Llama 3 is a collection of pretrained and fine-tuned generative text models ranging in scale from 8 billion to 70 billion parameters.\n`,
    provider: 'groq',
    provider_name: 'Meta',
    provider_brand: 'meta',
    requires_better_ai: true,
    speed: 5,
    intelligence: 3,
    context: 8,
    suggestions: ['chat', 'quick_ai', 'commands'],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {},
    in_better_ai_subscription: true,
    status: null,
  },
  {
    id: 'mixtral-8x7b-32768',
    model: 'mixtral-8x7b-32768',
    name: 'Mixtral 8x7B 32768',
    description: `A pretrained generative Sparse Mixture of Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward networks) for a total of 47 billion parameters.\n`,
    provider: 'groq',
    provider_name: 'Mistral AI',
    provider_brand: 'mistral',
    requires_better_ai: false,
    speed: 5,
    intelligence: 3,
    context: 7,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {},
    in_better_ai_subscription: false,
    status: null,
  },
]

export const GEMINI_SERVICE_PROVIDERS: RaycastAIModels = [
  {
    id: 'gemini-pro',
    model: 'gemini-pro',
    name: 'Gemini Pro',
    description: `Gemini Pro is a Google's model. It's a foundation model that performs well at a variety of natural language tasks such as summarization, instruction following, content generation, sentiment analysis, entity extraction, classification etc`,
    provider: 'gemini',
    provider_name: 'Google',
    provider_brand: 'google',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 16,
    suggestions: ['chat', 'quick_ai', 'commands'],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      // web_search: 'null'
    },
    in_better_ai_subscription: false,
    status: 'beta',
  },
]

export const COHERE_SERVICE_PROVIDERS: RaycastAIModels = [
  {
    id: 'command-light-nightly',
    model: 'command-light-nightly',
    name: 'Command Light Nightly',
    description: `Command Light Nightly is an instruction-following conversational model that performs language tasks at a higher quality, more reliably, and with a longer context than previous models. It is best suited for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.`,
    provider: 'cohere',
    provider_name: 'Cohere',
    provider_brand: 'openai',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 8,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      web_search: 'full',
    },
    in_better_ai_subscription: false,
    status: null,
  },
  {
    id: 'command-light',
    model: 'command-light',
    name: 'Command Light',
    description: `Command Light is an instruction-following conversational model that performs language tasks at a higher quality, more reliably, and with a longer context than previous models. It is best suited for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.`,
    provider: 'cohere',
    provider_name: 'Cohere',
    provider_brand: 'openai',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 4,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      web_search: 'full',
    },
    in_better_ai_subscription: false,
    status: null,
  },
  {
    id: 'command',
    model: 'command',
    name: 'Command',
    description: `Command is an instruction-following conversational model that performs language tasks at a higher quality, more reliably, and with a longer context than previous models. It is best suited for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.`,
    provider: 'cohere',
    provider_name: 'Cohere',
    provider_brand: 'openai',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 4,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      web_search: 'full',
    },
    in_better_ai_subscription: false,
    status: null,
  },
  {
    id: 'command-nightly',
    model: 'command-nightly',
    name: 'Command Nightly',
    description: `Command Nightly is an instruction-following conversational model that performs language tasks at a higher quality, more reliably, and with a longer context than previous models. It is best suited for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.`,
    provider: 'cohere',
    provider_name: 'Cohere',
    provider_brand: 'openai',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 8,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      web_search: 'full',
    },
    in_better_ai_subscription: false,
    status: null,
  },
  {
    id: 'command-r',
    model: 'command-r',
    name: 'Command R',
    description: `Command R is an instruction-following conversational model that performs language tasks at a higher quality, more reliably, and with a longer context than previous models. It is best suited for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.`,
    provider: 'cohere',
    provider_name: 'Cohere',
    provider_brand: 'openai',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 128,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      web_search: 'full',
    },
    in_better_ai_subscription: false,
    status: null,
  },
  {
    id: 'command-r-plus',
    model: 'command-r-plus',
    name: 'Command R+',
    description: `Command R+ is an instruction-following conversational model that performs language tasks at a higher quality, more reliably, and with a longer context than previous models. It is best suited for complex RAG workflows and multi-step tool use.`,
    provider: 'cohere',
    provider_name: 'Cohere',
    provider_brand: 'openai',
    requires_better_ai: false,
    speed: 3,
    intelligence: 3,
    context: 128,
    suggestions: [],
    features: ['chat', 'quick_ai', 'commands', 'api', 'emoji_search'],
    capabilities: {
      // image_generation: 'null',
      web_search: 'full',
    },
    in_better_ai_subscription: false,
    status: null,
  },
]

export const RAYCAST_DEFAULT_MODELS = {
  chat: 'openai-gpt-3.5-turbo',
  quick_ai: 'openai-gpt-3.5-turbo',
  commands: 'openai-gpt-3.5-turbo',
  api: 'openai-gpt-3.5-turbo',
  emoji_search: 'openai-gpt-3.5-turbo',
}

export const RAYCAST_GEMINI_PRO_ONLY_MODELS = {
  chat: 'gemini-pro',
  quick_ai: 'gemini-pro',
  commands: 'gemini-pro',
  api: 'gemini-pro',
  emoji_search: 'gemini-pro',
}

export const RAYCAST_DEFAULT_GROQ_MODELS = {
  chat: 'llama3-70b-8192',
  quick_ai: 'llama3-70b-8192',
  commands: 'llama3-70b-8192',
  api: 'llama3-70b-8192',
  emoji_search: 'llama3-70b-8192',
}

export const OPENAI_OFFICIAL_ENDPOINT = 'https://api.openai.com/v1/chat/completions'
export const GEMINI_OFFICIAL_ENDPOINT = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent'
